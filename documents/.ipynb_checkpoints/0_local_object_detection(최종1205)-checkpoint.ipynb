{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 로컬 개발 코드\n",
    "- 로컬에서 주피터 노트북(Jupyter Notebook), 주피터 랩(JupyterLab) 또는 파이썬(Python)을 이용한다.\n",
    "- 사이킷 런(scikit-learn), 텐서플로우(tensorflow), 파이토치(pytorch)를 사용하여 딥러닝 프로그램을 개발한다.\n",
    "- 파일명: 0_local_object_detection.ipynb\n",
    "\n",
    "### 로컬 개발 워크플로우(workflow)\n",
    "- 로컬 개발 워크플로우를 다음의 4단계로 분리한다.\n",
    "\n",
    "1. **데이터 세트 준비(Data Setup)**\n",
    "- 로컬 저장소에서 전처리 및 학습에 필요한 학습 데이터 세트를 준비한다.\n",
    "- 데이터 출처:\n",
    "- https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=178\n",
    "- https://public.roboflow.com/object-detection/pothole\n",
    "\n",
    "2. **데이터 전처리(Data Preprocessing)**\n",
    "- 데이터 세트의 분석 및 라벨링 파일의 type 변환 등의 전처리를 수행한다.\n",
    "    - 데이터세트 분석: 카테고리의 균일화 과정(고용량 대용량 업로드 문제로 사전에 처리하여 진행한 상태)\n",
    "    - 라벨링 데이터 : 준비된 Annotaion 라벨링 데이터를 COCO 라벨링 형식에서 YOLO 라벨링 형식으로 변환한다.\n",
    "    - 데이터를 모델 학습에 사용할 수 있도록 가공한다.\n",
    "\n",
    "3. **학습 모델 훈련(Train Model)**\n",
    "- 데이터를 훈련에 사용할 수 있도록 가공한 뒤에 학습 모델을 구성한다.\n",
    "- 학습 모델을 준비된 데이터 세트로 훈련시킨다.\n",
    "- mAP(Mean Average Precision)나 손실(Loss)등 학습 모델의 성능을 검증한다.\n",
    "- 학습 모델의 성능 검증 후, 학습 모델을 배포한다.\n",
    "- 배포할 학습 모델을 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "4. **추론(Inference)**\n",
    "- 저장된 전처리 객체나 학습 모델 객체를 준비한다.\n",
    "- 추론에 필요한 테스트 데이터 세트를 준비한다.\n",
    "- 배포된 학습 모델을 통해 테스트 데이터에 대한 추론을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 도로 위험물 객체탐지(Object Detection)\n",
    "- 지금부터 이미지와 동영상 데이터를 이용하여 위험물 객체 탐지를 진행해보고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 사용할 데이터\n",
    "---\n",
    "- AI HUB\n",
    "- roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### **AI HUB**\n",
    "![image](https://aihub.or.kr/web-nas/aihub21/files/public/inline-images/2020-02-062-1_0.png)\n",
    "\n",
    "- AI HUB에서 제공하는 Open Dataset인 [도로 장애물 표면 인지 영상(수도권 외)](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=178)이라는 **광역시, 고속도로, 국도 등 도로상의 장애물 및 도로 표면의 이상 상태 인지를 위한 영상 및 이미지 데이터셋**으로 11가지 카테고리 이미지 프레임이 존재한다. 우리는 이 중에서 다음 6개의 카테고리 이미지 데이터만 사용하고자 한다.\n",
    "- 해당 데이터셋은 **png형태의 원본 이미지**와 **json형태의 라벨링 이미지**로 구성되어 있다. 라벨링 박스의 좌표는 COCO방식으로 이루어져있다.\n",
    "- 사용할 데이터셋의 원본 이미지와 라벨링 이미지의 관계를 파악하고 라벨링 형식의 구성을 확인하고 이해한다.\n",
    "\n",
    "### **roboflow**\n",
    "![image](https://i.imgur.com/7Xz8d5M.gif)\n",
    "\n",
    "- roboflow에서 제공하는 Public Dataset인 [pothole Dataset](https://public.roboflow.com/object-detection/pothole)이라는 이것은 움푹 들어간 곳이 표시된 665개의 도로 이미지 모음입니다.\n",
    "AI허브에서도 포트홀 이미지가 제공되지만 균열, 매우 작은 포트홀 등 위험요소로 보기 힘든 이미지가 많아 포트홀만 이 데이터셋으로 대체하였고 665개의 이미지를 모두 사용하고자 한다.\n",
    "- 해당 데이터셋은 **jpg형태의 원본 이미지**와 **txt형태의 라벨링 이미지**로 구성되어 있습니다.라벨링 박스의 좌표는 YOLO방식으로 이루어져있다.\n",
    "\n",
    "#### **사용할 7개의 위험물 카테고리**\n",
    "- 아래의 7가지 카테고리는 골목에서 이륜차에게 위험요소가 될만한 **위험요소**와 오탐지를 방지하기 위한 **오탐지 방지용** 2가지의 기준에 부합하는 요소들을 선정하였다.\n",
    "1.위험요소(라바콘, 공사표지판, 쓰레기, 포트홀) 2. 오탐지방지용(사람, 정상수리된 포트홀, 맨홀)\n",
    "\n",
    "- AI HUB\n",
    "    - Person(사람)\n",
    "    - Traffic cone(라바콘)\n",
    "    - Construction signs & Parking prohibited board(공사표지판)\n",
    "    - Garbage bag & sacks(쓰레기)\n",
    "    - Filled pothole(정상수리된 포트홀)\n",
    "    - Manhole(정상도로의 맨홀)\n",
    "\n",
    "- roboflow\n",
    "    - Pothole(포트홀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, sys, time, random, glob, json, torch, yaml, zipfile, cv2\n",
    "import glob, json, os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from pylabel import importer\n",
    "from model.yolov5.detect import run\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. 데이터셋 준비(Data Setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 학습 카테고리를 균일화 시키는 과정\n",
    "- 이 과정은 사용하는 원본 데이터셋 용량 업로드 문제로 학습할 분량의 데이터만 추출하여 images, Annotation 폴더에 저장해두었다.\n",
    "- 카테고리별 사용한 이미지 개수\n",
    "    - 665장: Person(사람)\n",
    "    - 665장: Traffic cone(라바콘)\n",
    "    - 665장: Construction signs & Parking prohibited board(공사표지판)\n",
    "    - 318장: Garbage bag & sacks(쓰레기)\n",
    "    - 665장: Filled pothole(정상수리된 포트홀)\n",
    "    - 665장: Manhole(정상도로의 맨홀)\n",
    "    - 665장: Pothole(포트홀)\n",
    "- 위와 같이 추출한 이유는 roboflow의 포트홀 이미지가 665장이므로 다른 데이터셋도 같은 개수로 맞춰주었다.\n",
    "- 쓰레기 카테고리의 경우, 절대적인 이미지 수가 부족해 318장만 추출하였다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset.zip 파일 압축 풀기\n",
    "zip_source_path = './dataset.zip'\n",
    "zip_target_path = './meta_data'\n",
    "\n",
    "extract_zip_file = zipfile.ZipFile(zip_source_path)\n",
    "extract_zip_file.extractall(zip_target_path)\n",
    "\n",
    "extract_zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image의 총 장수: 4308\n",
      "Label의 총 갯수: 665\n",
      "Annotation의 총 갯수: 3643\n"
     ]
    }
   ],
   "source": [
    "# 이미지, 라벨 데이터 확인\n",
    "img_path = './meta_data/dataset/images/'\n",
    "label_path = './meta_data/dataset/labels/'\n",
    "annotation_path = './meta_data/dataset/Annotations/'\n",
    "\n",
    "img_list = os.listdir(img_path)\n",
    "label_list = os.listdir(label_path)\n",
    "annotation_list = os.listdir(annotation_path)\n",
    "\n",
    "print(f'Image의 총 장수: {len(img_list)}')\n",
    "print(f'Label의 총 갯수: {len(label_list)}')\n",
    "print(f'Annotation의 총 갯수: {len(annotation_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 이미지 사이즈 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 1280\n",
      "height: 720\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image1 = Image.open(img_path + img_list[1000])\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(image1)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "imag1_size = image1.size\n",
    "print('width:', imag1_size[0])\n",
    "print('height:', imag1_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # 이미지 시각화\n",
    "image = img.imread(img_path + img_list[1000])\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **2. 데이터 전처리(Data Preprocessing)**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 데이터 준비 (Preparing Data)\n",
    "\n",
    "앞서 확인한 AI HUB와 roboflow의 데이터를 훈련에 사용할 수 있는 형태로 바꾸고자 한다.\n",
    "- 학습 카테고리를 균일화 시키는 과정\n",
    "    - 이 과정은 사용하는 원본 데이터셋의 용량이 커서 학습할 분량의 데이터만 추출하는 과정으로 미리 다운샘플링 하여 넣어 images, Annotation 폴더에 저장해두었다.\n",
    "\n",
    "- 라벨링 데이터 변환\n",
    "    - YOLOv5에서 라벨링 학습을 위해서는 YOLO방식의 라벨링 방식과, txt type 데이터가 요구되므로 json type, COCO방식의 라벨링 방식을 가진 라벨링 데이터를 전부 txt type과 YOLO방식의 라벨링 방식으로 변환해준다.\n",
    "        - COCO 라벨링 방식(x,y,w,h) -> x: 좌상단x, y: 좌상단y, w: bounding box의 width, h: bounding box의 height\n",
    "        - YOLO 라벨링 방식(x,y,w,h) -> x: bounding box 중심점의 x, y: bounding box 중심점의 y, w: bounding box의 width, h: bounding box의 h\n",
    "\n",
    "- 훈련(train) 및 검증(val) 데이터셋 생성\n",
    "    - 전체 데이터 중 일부는 훈련 (train)에 사용하고, 나머지 일부는 훈련된 모델의 성능을 검증(val)하기 위해 사용하고자 한다. (`train_test_split`)\n",
    "\n",
    "- train/val 이미지 경로를 txt파일로 저장\n",
    "    - YOLOv5가 동작에 사용되는 ymal파일 실행을 위해 txt type으로 이미지 경로 저장(`with open(): f.write()`)\n",
    "\n",
    "- ymal 파일 생성\n",
    "    - naems : 카테고리명\n",
    "    - nc : 카테고리 개수(카테고리명 순서대로 0 ~ nc-1의 인덱스 설정됨.)\n",
    "    - trian : train이미지 경로(train.txt)\n",
    "    - val : val이미지 경로(val.txt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### annotation 폴더 내의 json 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LABEL_PATH = './meta_data/dataset/Annotations/'\n",
    "LABEL_SAVE_PATH = './meta_data/dataset/labels'\n",
    "json_list = os.listdir(LABEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### json -> txt / COCO -> YOLO 포맷 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3643/3643 [01:03<00:00, 57.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(json_list):\n",
    "    dataset = importer.ImportCoco(LABEL_PATH + file)\n",
    "\n",
    "    # 좌표 변경을 위한 변수 지정\n",
    "    bbox_x = int(dataset.df.iloc[0].ann_bbox_xmin)\n",
    "    bbox_y = int(dataset.df.iloc[0].ann_bbox_ymin)\n",
    "    height = int(dataset.df.iloc[0].ann_bbox_height)\n",
    "    width = int(dataset.df.iloc[0].ann_bbox_width)\n",
    "    img_height = int(dataset.df.iloc[0].img_height)\n",
    "    img_width = int(dataset.df.iloc[0].img_width)\n",
    "\n",
    "    # 카테고리 id, 해당하는 이미지의 이름 정보\n",
    "    img_category = int(dataset.df.iloc[0].cat_id)\n",
    "    img_name = dataset.df.iloc[0].img_filename[:-3]\n",
    "\n",
    "    # 카테고리 id가 0~6안에 있어야하기 때문에 카테고리 id 재설정\n",
    "    if img_category == 2:\n",
    "        img_category = img_category - 1\n",
    "    elif img_category == 3:\n",
    "        img_category = img_category - 1\n",
    "    elif img_category == 4:\n",
    "        img_category = img_category - 1\n",
    "    elif img_category == 5:\n",
    "        img_category = img_category - 1\n",
    "    elif img_category == 9:\n",
    "        img_category = img_category - 4\n",
    "    elif img_category == 10:\n",
    "        img_category = img_category - 4\n",
    "\n",
    "    # img_height, img_width 정보 누락 방지\n",
    "    if img_height != 720:\n",
    "        img_height = 720\n",
    "    if img_width != 1280:\n",
    "        img_width = 1280\n",
    "\n",
    "    # COCO -> YOLO 포맷으로 바운딩 박스 좌표 기준 변경\n",
    "    dw = 1.0 / img_width\n",
    "    dh = 1.0 / img_height\n",
    "    x_center = bbox_x + width / 2.0\n",
    "    y_center = bbox_y + height / 2.0\n",
    "    x = x_center * dw\n",
    "    y = y_center * dh\n",
    "    w = width * dw\n",
    "    h = height * dh\n",
    "\n",
    "    # SAVE_PATH가 없으면 생성\n",
    "    if not os.path.exists(LABEL_SAVE_PATH):\n",
    "        os.makedirs(LABEL_SAVE_PATH)\n",
    "\n",
    "    # txt파일이 없으면 생성\n",
    "    if not os.path.isfile(LABEL_SAVE_PATH + '/' + img_name + 'txt'):\n",
    "        f = open(LABEL_SAVE_PATH + '/' + img_name + 'txt', 'w')\n",
    "        f.close()\n",
    "\n",
    "    # 변경된 좌표값, 카테고리 id를 이용해 txt포맷의 라벨링 데이터 생성\n",
    "    f = open(LABEL_SAVE_PATH + '/' + img_name + 'txt', 'a')\n",
    "    f.write(str(img_category) + ' ')\n",
    "    f.write(str(x) + ' ')\n",
    "    f.write(str(y) + ' ')\n",
    "    f.write(str(w) + ' ')\n",
    "    f.write(str(h) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 데이터 시각화\n",
    "- 최종 전처리된 이미지의 카테고리별 개수를 막대그래프로 시각화하여 카테고리 분포를 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4308/4308 [00:00<00:00, 13324.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# 학습 카테고리 분포 확인\n",
    "cat_name = [\"Pothole on road\",\n",
    "            \"Person\",\n",
    "            \"Garbage bag & sacks\",\n",
    "            \"Construction signs\",\n",
    "            \"Traffic cone\",\n",
    "            \"Filled pothole\",\n",
    "            \"Manhole\"]\n",
    "LABEL_SAVE_PATH = './meta_data/dataset/labels'\n",
    "label_list = os.listdir(LABEL_SAVE_PATH)\n",
    "\n",
    "# 라벨 정보를 불러와서 카테고리 id부분만 읽어서 리스트에 저장\n",
    "cat_list = []\n",
    "for label in tqdm(label_list):\n",
    "    f = open(LABEL_SAVE_PATH + '/' + label, 'r')\n",
    "    cat_list.append(int(f.readline()[:2]))\n",
    "    f.close()\n",
    "\n",
    "# 카테고리 빈도수 확인\n",
    "cat_count = []\n",
    "for i in range(0, 7):\n",
    "    cat_count.append(cat_list.count(i))\n",
    "\n",
    "# 그래프로 시각화\n",
    "plt.title(\"Train Category Status\", size=20)\n",
    "plt.bar(cat_name, cat_count, color=mcolors.TABLEAU_COLORS)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 파일 갯수: 4308\n"
     ]
    }
   ],
   "source": [
    "# 이미지 파일 리스트 생성\n",
    "DIR_LIST = os.path.abspath(r'./meta_data/dataset/images')\n",
    "DIR_PATH = os.path.abspath(r'./meta_data/dataset')\n",
    "train_img_list = glob(f'{DIR_LIST}/*.png')\n",
    "print(f'이미지 파일 갯수: {len(train_img_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 훈련 & 평가 데이터셋 생성\n",
    "- 전체 데이터셋 중 9:1의 비율로 훈련, 평가 데이터셋을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image 갯수: 3877\n",
      "Validation Image 갯수: 431\n"
     ]
    }
   ],
   "source": [
    "# train, validation 데이터 분리\n",
    "train_img_list, val_img_list = train_test_split(train_img_list,\n",
    "                                                train_size=0.9,\n",
    "                                                random_state=42)\n",
    "\n",
    "print(f'Train Image 갯수: {len(train_img_list)}')\n",
    "print(f'Validation Image 갯수: {len(val_img_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 학습, 테스트 데이터셋의 정보를 담은 txt파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train/val 이미지 경로 txt파일로 저장\n",
    "with open(f'{DIR_PATH}\\\\train.txt', 'w') as f:\n",
    "    f.write('\\n'.join(train_img_list) + '\\n')\n",
    "\n",
    "with open(f'{DIR_PATH}\\\\val.txt', 'w') as f:\n",
    "    f.write('\\n'.join(val_img_list) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Yaml 파일 최신화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml 파일 정보: {'names': ['Pothole on road', 'Person', 'Garbage bag & sacks', 'Construction signs & Parking prohibited board', 'Traffic cone', 'Filled pothole', 'Manhole'], 'nc': 7, 'train': 'C:\\\\DataScience\\\\T3Q\\\\플랫폼 최종 제출 양식\\\\T3Q_1_PLATFORM\\\\meta_data\\\\dataset\\\\train.txt', 'val': 'C:\\\\DataScience\\\\T3Q\\\\플랫폼 최종 제출 양식\\\\T3Q_1_PLATFORM\\\\meta_data\\\\dataset\\\\val.txt'}\n"
     ]
    }
   ],
   "source": [
    "# yaml 생성\n",
    "with open(f'{DIR_PATH}\\data.yaml', 'r') as f:\n",
    "    data = yaml.full_load(f)\n",
    "\n",
    "data['train'] = f'{DIR_PATH}\\\\train.txt'\n",
    "data['val'] = f'{DIR_PATH}\\\\val.txt'\n",
    "\n",
    "with open(f'{DIR_PATH}\\data.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "print(f'data.yaml 파일 정보: {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **3. 학습 모델 훈련 (Train Model)**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "command 명령어를 통해 제공되는 YOLOv5의 train.py 파일을 사용하여 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 모델 컴파일 및 학습(Compile and Train Model)\n",
    "eopchs ,batch size, img_size, optimizer, yolov5모델 구조, yolov5 가중치를 선택할 수 있다.\n",
    "\n",
    "- --epochs: 학습시킬 횟수 설정\n",
    "- --batch: 16\n",
    "- --data: 생성한 ymal파일을 통해 이미지경로가 저장된 txt파일에 접근하여 데이터를 불러온다.\n",
    "    - train/val/test 경로, 클래스 개수, 클래스 이름이 저장된 yaml파일의 경로\n",
    "- --cfg: 모델의 구조(yolov5s.yaml)\n",
    "- --weights: YOLOv5에서 제공하는 학습 가중치 설정(yolov5s.pt)\n",
    "    - cfg, weights 최소 둘 중 하나 입력\n",
    "- --name: 전체 학습 결과가 저장 될 폴더이름\n",
    "- 학습결과: runs\\train 폴더 안에 저장됨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file '.\\yolo_v5_model\\train.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python.\\yolo_v5_model\\train.py --batch 16 --epochs 50 --data.\\dataset\\data.yaml --cfg.\\yolo_v5_model\\models\\yolov5s.yaml --weights yolov5s.pt --name train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 모델 평가\n",
    "1. 혼동행렬\n",
    "2. train,validation 비교 그래프\n",
    "3. 실제 학습된 label데이터와 학습된 모델의 예측 데이터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "address_matrix = r'.\\model\\yolov5\\runs\\train\\train_results\\confusion_matrix.png'\n",
    "address_graph = r'.\\model\\yolov5\\runs\\train\\train_results\\results.png'\n",
    "address_label = r'.\\model\\yolov5\\runs\\train\\train_results\\val_batch0_labels.jpg'\n",
    "address_pred = r'.\\model\\yolov5\\runs\\train\\train_results\\val_batch0_pred.jpg'\n",
    "\n",
    "# # 이미지, 라벨 시각화\n",
    "matrix = img.imread(address_matrix)\n",
    "graph = img.imread(address_graph)\n",
    "label = img.imread(address_label)\n",
    "pred = img.imread(address_pred)\n",
    "\n",
    "# 혼동행렬\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('confusion metirix')\n",
    "plt.imshow(matrix)\n",
    "\n",
    "# box_loss, object_loss, class_loss, presicion, recall, mAP_0.5, mAP_0.5:0.95\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('graph')\n",
    "plt.imshow(graph)\n",
    "\n",
    "# 학습할 때 사용한 라벨링 데이터\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title('label')\n",
    "plt.imshow(label)\n",
    "\n",
    "# 학습모델이 예측한 데이터\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title('predict')\n",
    "plt.imshow(pred)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **4. 추론 (Inference)**\n",
    "---\n",
    "훈련시킨 모델을 직접 사용해보고자 한다. 잘 훈련된 모델이라면 우리가 촬영한 이미지나 동영상이 주어졌을 때, 그 이미지나, 동영상의 카테고리를 bounding box로 detecting할 것이다. 그 과정을 진행보고자 한다.\n",
    "\n",
    "- 이미지 또는 동영상 준비\n",
    "- yolov5 모델에 위에서 학습한 모델 가중치를 설정하여 테스트\n",
    "- 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 이미지 또는 동영상 준비\n",
    "예제에서는 미리 준비해둔 이미지와 동영상 파일을 대신 받아 추론을 진행해보고자 한다.\n",
    "실제 사용자가 자신의 이미지 또는 동영상을 만들어 실행해볼 수도 있다.\n",
    "- 이미지, 동영상 생성법\n",
    "    1. 직접 촬영한 이미지 또는 동영상을 저장한다.\n",
    "    2. 지원 이미지 포맷: 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm'\n",
    "    3. 지원 동영상 포맷: 'asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv'\n",
    "    3. bounding box로 객체 탐지할 카테고리로는 다음과 같은 목록이 있다.\n",
    "        - Person(사람)\n",
    "        - Traffic cone(라바콘)\n",
    "        - Construction signs & Parking prohibited board(공사표지판)\n",
    "        - Garbage bag & sacks(쓰레기)\n",
    "        - Filled pothole(정상수리된 포트홀)\n",
    "        - Manhole(정상도로의 맨홀)\n",
    "        - Pothole(포트홀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 추론 데이터셋 준비 / test_dataset.zip 파일 압축 풀기\n",
    "zip_source_path = './test_dataset.zip'\n",
    "zip_target_path = './meta_data'\n",
    "\n",
    "extract_zip_file = zipfile.ZipFile(zip_source_path)\n",
    "extract_zip_file.extractall(zip_target_path)\n",
    "\n",
    "extract_zip_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 추론 실행\n",
    "detect.py의 run 함수를 임포트 하여 사용한다.\n",
    "- weights : 가장 잘 학습된 가중치 best.pt를 사용한다.\n",
    "- conf-thres: cofidence score가 0.3 이상인 detecting box만 시각화(0~1까지 설정 가능)\n",
    "- source: 테스트할 이미지나 동영상 경로\n",
    "- line_thickness: bounding box의 line 두께를 설정한다.\n",
    "- project: detecting 결과가 저장되는 경로\n",
    "- view_img: 추론 결과 시각화 여부\n",
    "- 더 많은 parameter설명은 model\\yolov5\\detect.py line 54 run()함수 참고\n",
    "\n",
    "프레임마다 인식되는 카테고리명과 해당 카테고리 갯수를 확인할 수 있다.\n",
    "결과 이미지, 동영상은 는 지정한 경로 안에 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 테스트할 이미지 또는 영상 source 경로 설정\n",
    "source = r'.\\meta_data\\test_dataset\\V0F_HY_1505_20201227_101811_N_CH2_Busan_Sun_Mainroad_Day_51810.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 추론 결과\n",
    "bounding box와 conf_score가 시각화되어 표시된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-12-4 Python-3.8.13 torch-1.13.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7029004 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/1 C:\\DataScience\\T3Q\\   \\T3Q_1_PLATFORM\\meta_data\\test_dataset\\V0F_HY_1505_20201227_101811_N_CH2_Busan_Sun_Mainroad_Day_51810.png: 384x640 1 Garbage bag & sacks, 98.9ms\n",
      "Results saved to \u001B[1mmeta_data\\test_result\\exp3\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# 추론 결과: runs\\detect 폴더 안에 저장됨\n",
    "run(weights=r'.\\model\\yolov5\\runs\\train\\train_results\\weights\\best.pt',\n",
    "    source=source,\n",
    "    conf_thres=0.3,\n",
    "    line_thickness=2,\n",
    "    project=r'.\\meta_data\\test_result',\n",
    "    view_img=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "df95319d8ce4e1d89f5365ae10992bc1f65da593082b1d264e8f529830ec2f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}